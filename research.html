<!DOCTYPE html>

<html lang="en">

<head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- <base href="https://mptouzel.github.io"> -->
<base href="">
<meta name="keywords" content="Maximilian Puelma Touzel">
<meta name="pagetitle" content="Maximilian Puelma Touzel - Mila, Canada">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<link href="css/style.css" rel="stylesheet" type="text/css">
<!-- <link href="css/css5.css" rel="stylesheet" type="text/css"> -->

<style>
.content {
  max-width: 960px;
  margin: auto;
}
</style>

<title>Maximilian Puelma Touzel</title>

</head>
 
<body>
<div class="content">

<div id="topbar">
<div class="navbox"><a href="index.html"><b> Max Puelma Touzel</b></a></div>
<div class="navbox"><a href="research.html">research</a></div>
<div class="navbox"><a href="publications.html">publications</a></div>
<div class="navbox"><a href="teachingservice.html">teaching/service</a></div>
<div class="navbox"><a href="cv.html">cv/bio</a></div>
<div class="navbox"><a href="climaction.html">climate actionable</a></div>
<div id="backtotop"><a href="index.html#top">â†‘</a></div>
</div>

<img src="img/matta_mashup.jpg" style="max-width:100%;height:auto;" align="middle">
<div>
<table id="billiards" width="100%" align="right">
<tr>
<td width="260px" >
<!-- <hr style="border: 10px solid gray; border-radius: 5px;">s
<hr style="border: 5px dashed gray; border-radius: 5px;"> -->
<h0 id="publications" padding=0>Research</h0>
</td>
<td><!--  valign="middle"> -->
<canvas id="canvas" height="40" width="650"></canvas>  <!-- background: url('img/matta_mashup.jpg')"  -->
</td>
</tr>
</table>
</div>
<br>
<br>
<br>
    There are two important aspects to decision-making that I find especially fascinating and drive many of my current research questions. 

    <p>
        The first is <b>uncertainty</b>. It weaves together the major components of decision-making:
    <ul>
        <li>    <em> Efficiently representating the world</em><br>How do we abstract the world in a way that minimally distorts our ability to choose actions to achieve a goal? </li>
        <li>    <em>Profitably acting in the world</em><br>How does the uncertainty in our beliefs about the world transform into uncertainty about how valuable are the actions we can take in it? </li>
        <li>    <em>Forming goals </em><br>How do we form and select goals to pursue (ultimately defining what profitable means)? </li> 
    </ul>

    Why do we sometimes make the effort to reduce this uncertainty, while other times we simply account for it, or even neglect it outright, even at our peril? While we are typically frugal with cognitive effort, we are also often simply suboptimal with respect to instrumental reward. A decision utility that extends to cognitive/informational and affective/social value is one line of investigation. Another stems from acknowledging that we are typically misguided and misinformed by our social environment. We are a social species after all. 
    <!-- , even when acknowledging that we operate under bounded resources and 'good-enough' heuristics. Neuroscience work suggests this suboptimality is often just poor inference. -->
</p> 
    <p>
        The second aspect is thus how <b>social factors, personal values, and sense of identity</b> can play a prominent role in the decision-making process within an individual, but also collectively within a society. 
<!-- <p>
    Dynamics as iterates in an data-driven learning algorithm, ongoing neural activity, or agent-environment interaction is central to this interplay. I am interested in how the dynamics of learning agents (be it humans, other animals, or machines) implement decision-making.
    An exciting space for these questions lies in the intersection of neural dynamics, reinforcement learning, and the cognitive and systems neuroscience of decision-making. I develop theoretical and computational approaches in collaboration with diverse experimental groups. -->
    Many of the pressing societal problems of our time, from extremism to climate change inaction, rest on how we form beliefs while consuming information and dialoguing in social venues, increasingly curated by algorithms, on a range of scales from peer-to-peer extending to large, online communities. Through the way they bias how individuals decide what to believe, both the form of the information exchanged in these fundamentally social interactions and the form of the mediums over which they occur can play a role in the collective decisions we make as a society.
    <!--I am currently working with cognitive neuroscientists and psychologists on the dynamics of human decision-making and how it impacts the <a href="https://www.penguinrandomhouse.com/books/566677/human-compatible-by-stuart-russell/">AI alignment problem</a>. -->
    <!-- How can we quantify how we assess risk and how this capacity develops? -->
    <!-- As a mathematical theory of agent-environment interactions, reinforcement learning is useful when interpreting human decision-making.  -->
</p>
 <h1 >Applications</h1>
 <p>
    In my applied work, I collaborate with psychologists and social scientists in order to tease apart the interplay of belief, identity, and decision-making bias through laboratory experiments and population data. By <b> better accounting for the effects of the social milieu in which individuals come to believe who they are and what is important to them</b>, we can better  <a href="https://www.penguinrandomhouse.com/books/566677/human-compatible-by-stuart-russell/">align the algorithms</a> that structure our collective discourse, as well as develop prosocial, assistive technologies in that space. I organized a <a href="https://sites.google.com/mila.quebec/soc-rldm/home">RLDM workshop on social alignment in humans and machines</a> on this topic.
    <!--through decision-making tasks and large questionnaires. Using climate change as an application, I have also begun research into how this risk assessment is impacted by our existing beliefs.-->
    <h2 >Example Projects</h2>

<ul>
    <li>Using <b>topic correlations inferred from open-ended responses to large scale surveys</b> about climate change beliefs (here about a tax on carbon) in pursuit of better climate and policy communication. Below is a projection of the learned LDA-like topic model onto 2 topics (red/blue). (Note this corpus has been stemmed so 'reduc' here accounts for 'reduction', 'reducing', etc.). [with E. Lachapelle (SciPo, UdeM)]</li>
    <center>
<img src="img/topic18embedding.png" style="max-width:50%;height:auto;" align="middle" border=1>
</center>
<br>
    <li>Using <b>reward maps inferred with inverse reinforcement learning from dynamic-risk task behaivour</b> as an efficient, language-free proxy for subject impulsivity scores. [with P. Cisek (Neuroscience, UdeM)]</li>
     <center><img src="img/papers/2022IRL.png" style="max-width:30%;height:auto;" align="middle"></center>
</ul>
</p>
<h1>Theory</h1>
<p>
    My theory work is motivated from the fact that decision-making and belief formation is an ongoing-process not easily accessed via single tasks performed in restrictive environments. I am currently funded under the Canadian Excellence Research Chair in autonomous AI held by Irina Rish (UdeM). With students in her group, we analyze the subtle dynamics that emerge in <b>multi-agent, continual reinforcement learning settings</b>, providing a controlled modelling sandbox for develeping theory, as well as to help understand complex social decision-making phenomena in natural systems.
    <h2 >Example Projects</h2>

<ul>
    <li><b>Understanding how, as decision-making problems scale, the time to learn about them grows according to the ways in which the agent and the environment interact. </b><br>
    <em>Continual Learning In Environments With Polynomial Mixing Times</em><br>
    Riemer M*, Chandra Raparthy S*, Cases I, Subbaraj G, Puelma Touzel M, Rish I.<br>
    <em>Ecological Reinforcement Learning Workshop, NeurIPS </em>(2021). 
</li>
<br>
    <li><b>The world is full of other behaving and learning agents. How can the complexity of what everyone else is doing be abstracted efficiently? </b><br>
        <em>Summarizing Societies: Agent Abstraction in Multi-Agent Reinforcement Learning</em><br>
Puelma Touzel M*, Me'marian A*, Bhati R, Riemer M, Rish I.<br>
<em>From Cells to Societies: Learning Across Scales Workshop, ICLR</em> (2022). 
        </li>
</ul>
</p>
</p>
<h1>Statistical Physics</h1>
<p>
    Finally, I have a long-standing interest in <b> formulating information processing of a given learning system's dynamics using theoretical statistical physics</b>. 

    <h2 >Example Project</h2>

<ul>
    <li><b>Extending the formalism of information engines from stochastic thermodynamics to machine learning algorithms</b>. Here, a thermodynamics of the system's stochastic dynamics reveals information processing as buried in its entropy production.<br>
    <a href="https://umontreal.zoom.us/rec/play/rZOe6DTE_Pjw-XY0_6vnSljxmpZD0lofswX2db4KbbF1i6zg2VqImXI6iDP6iwKfJdYR_cQxB0gR4rqR.69VNYXhWGy4aLto4?continueMode=true&_x_zm_rtaid=l7x44w80Qo2NzF66O4ZfTA.1648247768967.b5bd9133398959dd4d7ef1dc6448db17&_x_zm_rhtaid=626">Talk</a> on Stochastic Thermodynamics of learning to the Physics of Machine learning reading group at Mila.</li>
</ul>
</p>


</p>
</div>
<p>
    <br>
    <div style="display: flex; justify-content: center;">
   <img src="graphic.jpg" style="width:240px;height:60px;">
        </div>
</body>
</html>

