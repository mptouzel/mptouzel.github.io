<!DOCTYPE html>

<html lang="en">

<head>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- <base href="https://mptouzel.github.io"> -->
<base href="">
<meta name="keywords" content="Maximilian Puelma Touzel">
<meta name="pagetitle" content="Maximilian Puelma Touzel - Mila, Canada">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<link href="css/style.css" rel="stylesheet" type="text/css">
<!-- <link href="css/css5.css" rel="stylesheet" type="text/css"> -->

<style>
.content {
  max-width: 960px;
  margin: auto;
}
</style>

<title>Maximilian Puelma Touzel</title>

</head>
 
<body>
<div class="content">

<div id="topbar">
<div class="navbox"><a href="index.html"><b> Max Puelma Touzel</b></a></div>
<div class="navbox"><a href="research.html">research</a></div>
<div class="navbox"><a href="publications.html">publications</a></div>
<div class="navbox"><a href="teachingservice.html">teaching/service</a></div>
<div class="navbox"><a href="cv.html">cv/bio</a></div>
<div class="navbox"><a href="climaction.html">climate actionable</a></div>
<div id="backtotop"><a href="index.html#top">â†‘</a></div>
</div>

<img src="img/matta_mashup.jpg" style="max-width:100%;height:auto;" align="middle">
<div>
<table id="billiards" width="100%" align="right">
<tr>
<td width="260px" >
<!-- <hr style="border: 10px solid gray; border-radius: 5px;">s
<hr style="border: 5px dashed gray; border-radius: 5px;"> -->
<h0 id="publications" padding=0>Research</h0>
</td>
<td><!--  valign="middle"> -->
<canvas id="canvas" height="40" width="650"></canvas>  <!-- background: url('img/matta_mashup.jpg')"  -->
</td>
</tr>
</table>
</div>
<br>
<br>
<br>
    There are two important aspects to human decision-making that I find especially fascinating.

<p>
    The first is <b>uncertainty</b>. It weaves together the major components of decision-making theory:
    <ul>
        <li>    <em> Efficiently representating the world</em><br>How do we abstract the world in a way that minimally distorts our ability to choose actions to achieve a goal? </li>
        <li>    <em>Profitably acting in the world</em><br>How does the uncertainty in our beliefs about the world transform into uncertainty about how valuable are the actions we can take in it? </li>
        <li>    <em>Forming goals </em><br>How do we form and select goals to pursue (ultimately defining what profitable means)? </li> 
    </ul>

    Why do we sometimes make the effort to reduce this uncertainty, while other times we simply account for it, or even neglect it outright, even at our peril? While we are typically frugal with cognitive effort, we are also often simply suboptimal with respect to instrumental reward. A decision utility that extends to cognitive/informational and affective/social value is one line of investigation. Another stems from acknowledging that we misinterpret or are misguided and misinformed by our social environment. We are a social species after all. 
    <!-- , even when acknowledging that we operate under bounded resources and 'good-enough' heuristics. Neuroscience work suggests this suboptimality is often just poor inference. -->
</p> 
<p>
    The second aspect is thus how <b>social factors, personal values, and sense of identity</b> can play a prominent role in the decision-making process within an individual, but also collectively within a society. 
<!-- <p>
    Dynamics as iterates in an data-driven learning algorithm, ongoing neural activity, or agent-environment interaction is central to this interplay. I am interested in how the dynamics of learning agents (be it humans, other animals, or machines) implement decision-making.
    An exciting space for these questions lies in the intersection of neural dynamics, reinforcement learning, and the cognitive and systems neuroscience of decision-making. I develop theoretical and computational approaches in collaboration with diverse experimental groups. -->
    Many of the pressing societal problems of our time, from polarization to climate change inaction (see <a href="climaction.html"><b>climate actionable</b></a>), rest on how we form beliefs while consuming information and dialoguing in social venues, increasingly curated by algorithms, on a range of scales from peer-to-peer extending to large, online communities. The form of the information exchanged in these fundamentally social interactions and the form of the mediums over which this exchange occurs can play a role in the collective decisions we make as a society by biasing how individuals decide what to believe.</p>
    <center><img src="img/intersection.jpg" style="max-width:70%;height:auto;" align="middle"></center>
<p>
    These interests land me at the various intersections of (1) <em>cognitive psychology/behavioural science</em>, (2) <em>public policy/opinion research</em>, and (3) <em>computational social science</em>. My approach to these questions is heavily influenced by my physics of complex systems training. I develop data-driven models of human individual and collective behaviour to understand the nature of these contemporary societal challenges with the aim of informing better responses. The dynamics and learning of these models use statistical machine learning tools which I interpret through a statistical physics and dynamical systems lens.  I am excited to take part in the modern trend of pushing the theory of games & reinforcement learning towards contact with data to better understand real-world multi-agent systems. I am also excited to use my research community building experience in this space. There are already initiatives pulling people together on this (e.g. Work On Climate's <a href="https://www.notion.so/Social-Science-Learning-Group-a5af44ee3d4642438750466b44d1ee32">Social Science Learning Group</a> and this Mila-supported <a href="https://blog.salesforceairesearch.com/ai4climatecoop/">AI for Global Climate Cooperation</a> initiative that I am involved in). 
</p>


    <!--I am currently working with cognitive neuroscientists and psychologists on the dynamics of human decision-making and how it impacts the <a href="https://www.penguinrandomhouse.com/books/566677/human-compatible-by-stuart-russell/">AI alignment problem</a>. -->
    <!-- How can we quantify how we assess risk and how this capacity develops? -->
    <!-- As a mathematical theory of agent-environment interactions, reinforcement learning is useful when interpreting human decision-making.  -->

 <h1 >Applications</h1>
 <p>
    In my applied work, I collaborate with psychologists and social scientists in order to tease apart the interplay of belief, identity, and decision-making bias through laboratory experiments and population data. By <b> better accounting for the effects of the social milieu in which individuals come to believe who they are and what is important to them</b>, we can better  <a href="https://www.penguinrandomhouse.com/books/566677/human-compatible-by-stuart-russell/">align the algorithms</a> that structure our collective discourse, as well as develop prosocial, assistive technologies in that space. I organized a <a href="https://sites.google.com/mila.quebec/soc-rldm/home">RLDM workshop on social alignment in humans and machines</a> on this topic.
    <!--through decision-making tasks and large questionnaires. Using climate change as an application, I have also begun research into how this risk assessment is impacted by our existing beliefs.-->
    <h2 >Example Projects</h2>

<ul>
    <li>Using <b>topic correlations inferred from open-ended responses to large scale surveys</b> about climate change beliefs (here about a tax on carbon) to operationalize ideology in pursuit of better climate and policy communication. [with E. Lachapelle (UdeM)]</li>
    
<div class="parent">
    <iframe class="image1" style="border: none; position: relative;top: 0;left: 0;" src="graphic_test.html" scrolling="no" height=600px; width=65% ></iframe>
    <img class="image2" src="img/topmod.png" width=65%/>
  </div>
<br>
    <li>Using <b>reward maps inferred with inverse reinforcement learning from dynamic-risk task behaivour</b> as an efficient, language-free proxy for subject impulsivity scores. [with P. Cisek (UdeM)]</li>
     <center><img src="img/papers/2022IRL.png" style="max-width:40%;height:auto;" align="middle"></center>
     <br>
     <li>New project on detection of conflict-sorting (stay tuned for details!).</li>
</ul>
</p>
<h1>Theory</h1>
<p>
    My theory work is motivated from the fact that decision-making and belief formation is an ongoing-process not easily accessed via single tasks performed in restrictive environments. I am currently funded under the Canadian Excellence Research Chair in autonomous AI held by Irina Rish (UdeM). With students in her group, we analyze the subtle dynamics that emerge in <b>multi-agent, continual reinforcement learning settings</b>, providing a controlled modelling sandbox for develeping theory, as well as to help understand complex social decision-making phenomena in natural systems.
    <h2 >Example Projects</h2>

<ul>
    <li><b>Understanding how, as decision-making problems scale, the time to learn about them grows according to the ways in which the agent and the environment interact. </b><br>
    <em>Continual Learning In Environments With Polynomial Mixing Times</em><br>
    Riemer M*, Chandra Raparthy S*, Cases I, Subbaraj G, Puelma Touzel M, Rish I.<br>
    <em>NeurIPS</em> (2022). 
</li>
<br>
    <li><b>The world is full of other behaving and learning agents. How can the complexity of what everyone else is doing be abstracted efficiently? </b><br>
        <em>Summarizing Societies: Agent Abstraction in Multi-Agent Reinforcement Learning</em><br>
Puelma Touzel M*, Me'marian A*, Bhati R, Riemer M, Rish I.<br>
<em>From Cells to Societies: Learning Across Scales Workshop, ICLR</em> (2022). 
        </li>
</ul>
</p>
</p>
<h1>Statistical Physics</h1>
<p>
    Finally, I have a long-standing interest in <b> formulating information processing of a given learning system's dynamics using theoretical statistical physics</b>. This beautiful line of work that I follow arises mostly from the nice <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.99.052140">correspondence between Bayesian inference and equilibrium thermodynamics</a>. The correspondence is deep, e.g. the Nishimori line of spin glass phases maps to the case when a decoder has exact knowledge of the communication channel. There are many other beautiful connections: <a href="https://proceedings.mlr.press/v75/wibisono18a.html">sampling as optimization in the space of measures</a>, Entropy regularization/MaxEnt RL, ...

    <h2 >Example Project</h2>

<ul>
    <li><b>Extending the formalism of information engines from stochastic thermodynamics to machine learning algorithms</b>. Here, a thermodynamics of the system's stochastic dynamics reveals information processing as buried in its entropy production.<br>
    <a href="https://umontreal.zoom.us/rec/play/rZOe6DTE_Pjw-XY0_6vnSljxmpZD0lofswX2db4KbbF1i6zg2VqImXI6iDP6iwKfJdYR_cQxB0gR4rqR.69VNYXhWGy4aLto4?continueMode=true&_x_zm_rtaid=l7x44w80Qo2NzF66O4ZfTA.1648247768967.b5bd9133398959dd4d7ef1dc6448db17&_x_zm_rhtaid=626">Talk</a> on Stochastic Thermodynamics of learning to the Physics of Machine learning reading group at Mila.</li>
</ul>
</p>


</p>
</div>
<p>
    <br>
    <div style="display: flex; justify-content: center;">
   <img src="graphic.jpg" style="width:240px;height:60px;">
        </div>
</body>
</html>

